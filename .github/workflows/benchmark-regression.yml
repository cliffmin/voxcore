name: Benchmark Regression Tests

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]
  workflow_dispatch:  # Manual trigger
  schedule:
    - cron: '0 0 * * 0'  # Weekly on Sunday at midnight

jobs:
  baseline-benchmark:
    name: Baseline Regression Test
    runs-on: macos-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v6
        with:
          lfs: true

      - name: Install whisper-cpp
        run: |
          brew install whisper-cpp

      - name: Set up Java 17
        uses: actions/setup-java@v5
        with:
          distribution: 'temurin'
          java-version: '17'

      - name: Build voxcore CLI
        run: |
          cd whisper-post-processor
          ./gradlew clean voxcoreJar

      - name: Create voxcore CLI wrapper
        run: |
          VOXJAR=$(ls "$GITHUB_WORKSPACE/whisper-post-processor/build/libs/voxcore"*.jar 2>/dev/null | head -1)
          if [ -z "$VOXJAR" ]; then echo "voxcore JAR not found"; exit 1; fi
          cat > /tmp/voxcore << EOF
          #!/usr/bin/env bash
          exec java -jar "$VOXJAR" "\$@"
          EOF
          chmod +x /tmp/voxcore

      - name: Run baseline benchmark
        id: benchmark
        run: |
          # Uses golden-public dataset (committed synthetic fixtures)
          VOXCORE_CLI=/tmp/voxcore \
          GOLDEN_DIR=tests/fixtures/golden-public \
          BENCHMARK_OUTPUT=benchmark-results.json \
          ./scripts/utilities/benchmark_cli.sh | tee benchmark-results.txt

          # Extract metrics
          AVG_ACCURACY=$(grep "Avg accuracy:" benchmark-results.txt | awk '{print $3}' | tr -d '%')
          AVG_TIME=$(grep "Avg time:" benchmark-results.txt | awk '{print $3}' | tr -d 'ms')

          echo "avg_accuracy=$AVG_ACCURACY" >> $GITHUB_OUTPUT
          echo "avg_time=$AVG_TIME" >> $GITHUB_OUTPUT

      - name: Check regression thresholds
        if: steps.benchmark.outputs.avg_accuracy != ''
        run: |
          AVG_ACCURACY=${{ steps.benchmark.outputs.avg_accuracy }}
          AVG_TIME=${{ steps.benchmark.outputs.avg_time }}

          # Baseline thresholds (v0.7.0 local with vocab: 59%, 1083ms; CI runs without VoxCompose)
          MIN_ACCURACY=38  # Must not drop below 38% (CI has no vocabulary hints)
          MAX_TIME=2000    # Must not exceed 2000ms

          echo "=== Regression Check ==="
          echo "Accuracy: ${AVG_ACCURACY}% (threshold: >=${MIN_ACCURACY}%)"
          echo "Speed: ${AVG_TIME}ms (threshold: <=${MAX_TIME}ms)"

          FAILED=0

          if [ "$AVG_ACCURACY" -lt "$MIN_ACCURACY" ]; then
            echo "FAIL: Accuracy ${AVG_ACCURACY}% below threshold ${MIN_ACCURACY}%"
            FAILED=1
          else
            echo "PASS: Accuracy within threshold"
          fi

          if [ "$AVG_TIME" -gt "$MAX_TIME" ]; then
            echo "FAIL: Speed ${AVG_TIME}ms exceeds threshold ${MAX_TIME}ms"
            FAILED=1
          else
            echo "PASS: Speed within threshold"
          fi

          if [ "$FAILED" -eq 1 ]; then
            echo ""
            echo "Regression detected! Performance has dropped below acceptable thresholds."
            echo "See tests/results/baselines/ for historical baselines."
            exit 1
          fi

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: benchmark-results
          path: |
            benchmark-results.txt
            benchmark-results.json
          retention-days: 90

      - name: Comment PR with results
        if: github.event_name == 'pull_request' && steps.benchmark.outputs.avg_accuracy != ''
        uses: actions/github-script@v8
        with:
          script: |
            const accuracy = '${{ steps.benchmark.outputs.avg_accuracy }}';
            const time = '${{ steps.benchmark.outputs.avg_time }}';
            const body = [
              '## Benchmark Results',
              '',
              '**Baseline (v0.7.0 local: 59% / 1083ms; CI runs without VoxCompose):**',
              `- Accuracy: ${accuracy}% (threshold: >=38%)`,
              `- Speed: ${time}ms (threshold: <=2000ms)`,
              '',
              Number(accuracy) >= 38 && Number(time) <= 2000
                ? 'All regression checks passed.'
                : 'Performance regression detected.',
              '',
              '<details>',
              '<summary>Details</summary>',
              '',
              'Download the `benchmark-results` artifact for full output.',
              '</details>'
            ].join('\n');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.name,
              body
            });

  # Feature-specific benchmarks (when datasets exist)
  feature-benchmarks:
    name: Feature-Specific Regression Tests
    runs-on: macos-latest
    if: false  # Disabled until feature datasets are created

    strategy:
      matrix:
        feature: [filler-words, word-separation, vocabulary]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Install dependencies
        run: |
          brew install whisper-cpp

      - name: Set up Java 17
        uses: actions/setup-java@v5
        with:
          distribution: 'temurin'
          java-version: '17'

      - name: Build voxcore CLI
        run: |
          cd whisper-post-processor
          ./gradlew clean voxcoreJar

      - name: Run ${{ matrix.feature }} benchmark
        run: |
          if [ -d "tests/fixtures/golden-features/${{ matrix.feature }}" ]; then
            VOXCORE_CLI=/tmp/voxcore \
            GOLDEN_DIR=tests/fixtures/golden-features/${{ matrix.feature }} \
            ./scripts/utilities/benchmark_cli.sh
          else
            echo "No dataset for ${{ matrix.feature }}, skipping"
          fi
